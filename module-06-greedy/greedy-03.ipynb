{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [],
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "div#notebook {\n",
       " font-family: \"Exo_2\", sans-serif;\n",
       "}\n",
       "\n",
       ".rendered_html h1,\n",
       ".text_cell_render h1 {\n",
       " color: #126dce;\n",
       " font-size: 220%;\n",
       " text-align: center;\n",
       " font-weight: lighter;\n",
       "}\n",
       ".rendered_html h2,\n",
       ".text_cell_render h2 {\n",
       " text-align: center;\n",
       " font-size: 170%;\n",
       " color: #126dce;\n",
       " font-style: normal;\n",
       " font-weight: lighter;\n",
       "}\n",
       ".rendered_html h3,\n",
       ".text_cell_render h3 {\n",
       " font-size: 150%;\n",
       " color: #126dce;\n",
       " font-weight: lighter;\n",
       " text-decoration: italic;\n",
       " font-style: normal;\n",
       "}\n",
       ".rendered_html h4,\n",
       ".text_cell_render h4 {\n",
       " font-size: 120%;\n",
       " color: #126dce;\n",
       " font-weight: underline;\n",
       " font-style: normal;\n",
       "}\n",
       ".rendered_html h5,\n",
       ".text_cell_render h5 {\n",
       " font-size: 100%;\n",
       " color: #2f2f2f;\n",
       " font-weight: lighter;\n",
       " text-decoration: underline;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# setup\n",
    "from IPython.core.display import display,HTML\n",
    "display(HTML('<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>'))\n",
    "display(HTML(open('rise.css').read()))\n",
    "\n",
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\", font_scale=1.5, rc={'figure.figsize':(12, 6)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CMPS 6610\n",
    "# Algorithms\n",
    "\n",
    "## Data Compression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Today's agenda:\n",
    "\n",
    "- Huffman Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fixed-length encoding\n",
    "\n",
    "Suppose we are given a document $D$ in which we use the alphabet $\\Sigma = \\{\\sigma_1 \\ldots \\sigma_k\\}$. Our goal is to create a binary encoding of $\\Sigma$ to represent $D$ with as few bits as possible. Of course, the encoding must distinctly represent $\\Sigma$.\n",
    "\n",
    "Example: Suppose $\\Sigma=\\{A, B, C, D\\}$, and document $D = \\langle A, A, A, A, A, A, A, A, A, B, C, D\\rangle$. \n",
    "\n",
    "The naive encoding could be \n",
    "\n",
    "|$$\\sigma$$|$$e(\\sigma)$$         |\n",
    "|-------|-----------------------|\n",
    "| A     | 00 |\n",
    "| B     | 01 |\n",
    "| C     | 10 | \n",
    "| D     | 11 |\n",
    "\n",
    "This is a **fixed-length** encoding of $\\Sigma$. What is the number of bits required to encode the entire document with this encoding?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The length of the document with this encoding is $2\\cdot 12 = 24$. The encoding is:\n",
    "\n",
    "$e(D) = \"000000000000000000011011\"$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Variable-length encoding\n",
    "\n",
    "\n",
    "Fixed-length encoding doesn't account for redundancy in the document. \n",
    "\n",
    "Let $f: \\sigma \\rightarrow \\mathbb{R}$ be the number of times a character appears in $D$; this is easily computed in $O(|D|)$ work. What about the span?\n",
    "\n",
    "Intuitively, we should encode the document by the frequency of the characters in the alphabet. The more frequent the character, the smaller its code should be.\n",
    "\n",
    "\n",
    "$D = \\langle A, A, A, A, A, A, A, A, A, B, C, D\\rangle$\n",
    "\n",
    "|$$\\sigma$$ | $$f(\\sigma)$$|\n",
    "|-------|---------------|\n",
    "| A     | 9 |\n",
    "| B     | 1 |\n",
    "| C     | 1 | \n",
    "| D     | 1 |\n",
    "\n",
    "\n",
    "\n",
    "So, following that logic, we could come up with a code like this:\n",
    "\n",
    "|$$\\sigma$$ |$$e'(\\sigma)$$|\n",
    "|-------|---------------|\n",
    "| A     | 0   |\n",
    "| B     | 1  |\n",
    "| C     | 00 | \n",
    "| D     | 11 |\n",
    "\n",
    "Is this a valid encoding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<br><br>\n",
    "How should we decode `11`? It's ambiguous between `B` and `DD`.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "Instead, we could use:\n",
    "\n",
    "\n",
    "|$$\\sigma$$ |$$e'(\\sigma)$$|\n",
    "|-------|---------------|\n",
    "| A     | 0   |\n",
    "| B     | 10  |\n",
    "| C     | 110 | \n",
    "| D     | 111 |\n",
    "\n",
    "This is a **variable-length** encoding, where each character may be encoded by a different number of bits.\n",
    "\n",
    "This leads to an encoding of $D = \\langle A, A, A, A, A, A, A, A, A, B, C, D\\rangle$ as:\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "$e'(D) = \"00000000010110111\"$\n",
    "\n",
    "<br><br>\n",
    "\n",
    "This has length $1\\cdot 9 + 2\\cdot 1 + 3\\cdot 1 + 3\\cdot 1 = 17$. So this is a bit better. \n",
    "\n",
    "In general, the cost of a given encoding $e$ is \n",
    "\n",
    "$$C(e) = \\sum_{i=0}^{|D|} |e(D[i])| = \\sum_{\\sigma\\in\\Sigma} f(\\sigma)\\cdot e(\\sigma).$$\n",
    "\n",
    "Over all possible valid encodings $e: \\Sigma \\rightarrow \\{0,1\\}^*$, we want to find a variable-length encoding $e_*$ so that $C(e_*)$ is minimized.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Encodings as Trees\n",
    "\n",
    "How do we ensure that a variable-length encoding is valid? In other words, how do we only consider variable-length encodings that are *prefix-free*?\n",
    "\n",
    "We can think of an encoding as representing a tree, with characters from $\\Sigma$ as leaves. Note that a fixed-length encoding has all leaves at the same level. \n",
    "\n",
    "For the two encodings we gave, we'd have:\n",
    "\n",
    "<img src = \"encoding_trees.jpg\" width=\"60%\">\n",
    "\n",
    "Every prefix-free encoding $e$ can be represented by a tree $T_e$. \n",
    "\n",
    "The depth of each character $d_T(\\sigma)$ in the tree determines how many bits are needed to encode $\\sigma$.\n",
    "\n",
    "So the optimal compression of $D$ can be achieved by identifying the encoding tree $T$ that minimizes:\n",
    "\n",
    "$$C(T) = \\sum_{\\sigma\\in\\Sigma} f(\\sigma)\\cdot d_T(\\sigma)$$\n",
    "\n",
    "We will come up with a greedy algorithm for constructing $T$ and show that it is optimal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Huffman Coding\n",
    "\n",
    "\n",
    "Intuitively we know we should ensure that when constructing an encoding tree, the higher the frequency, the shorter the path length.\n",
    "\n",
    "How about if we sort the frequencies in descending order and then assign tree positions in this order? But how do we guarantee the highest frequency characters have a short depth? \n",
    "\n",
    "We could group the characters into two sets of equal total frequency, this way the more frequent characters will have lower depth. This divide-and-conquer approach was developed by Shannon-Fano... but is not optimal.\n",
    "\n",
    "David Huffman (as a graduate student in Robert Fano's class) came up with a *bottom-up* greedy algorithm as a class project and was able to prove that it was optimal.\n",
    "\n",
    "The main idea of this algorithm is to choose the two **least** frequent characters $x$ and $y$ and create a subtree with $x$ and $y$ as sibling leaves for the final encoding. We then remove $x$ and $y$ from $\\Sigma$ and add a *new* character $z$ with frequency $f(x)+f(y)$, and recurse to compute a tree $T'$. The final tree $T$ is just $T'$ with $z$ replaced by the subtree with $x, y$ as siblings. \n",
    "\n",
    "<img src=\"huffman_example.jpg\" width=\"60%\">\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "### How can we use a min-heap to implement this algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We need to efficiently retrieve the next two smallest frequency nodes.\n",
    "\n",
    "\n",
    "![huffman-heap-2.png](huffman-heap-2.png)\n",
    "\n",
    "1. Initialize a min-heap with character frequencies $f(\\sigma)$\n",
    "\n",
    "Then, repeat:\n",
    "\n",
    "2. Call `deleteMin` twice to get the two least frequent nodes $x$ and $y$\n",
    "3. Create a new node $z$ with frequency $f(x) + f(y)$\n",
    "4. Make $x$ and $y$ children of $z$ in the tree.\n",
    "4. Call `insert` to add $z$ to the heap\n",
    "\n",
    "How many times will this repeat?\n",
    "\n",
    "<br><br>\n",
    "\n",
    "What is work/span of this algorithm?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Because we will always reduce the number of nodes by 1, this will repeat $n$ times (where $n = |\\Sigma|$).\n",
    "\n",
    "The cost of 2 calls to `deleteMin` and one call to `insert` is $3 \\lg n$.\n",
    "\n",
    "Thus, total work is $O(n \\lg n)$.\n",
    "\n",
    "We unfortunately have not exposed any parallelism in this algorithm, so the span is also $O(n \\lg n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Proof of Optimality\n",
    "\n",
    "**Greedy Choice**: Let $x, y\\in\\Sigma$ have the two smallest frequencies ($f(x) \\leq f(y)$). Then there is an optimal encoding $T$ for $\\Sigma$ with $x, y$ as sibling leaves at maximum depth. \n",
    "\n",
    "**Proof**: First let us observe that in an optimal solution $T^*$, $x$ must have maximum depth. Suppose that it did not, and some character $a$ with frequency $f(a)$ had depth $d_{T^*}(a) > d_{T^*}(x)$. Then we can construct a new tree $T^{**}$ with cost\n",
    "\n",
    "$\\begin{eqnarray*}\n",
    "C(T^{**}) &=& C(T^*) - f(a)d_{T^*}(a)  - f(x)d_{T^*}(x) + f(x)d_{T^*}(a) + f(a)d_{T^*}(x) \\\\\n",
    "&=& C(T^*) - (f(a)d_{T^*}(a) + f(x)d_{T^*}(x) - f(x)d_{T^*}(a) - f(a)d_{T^*}(x)) \\\\\n",
    "&=& C(T^*) - (f(a)-f(x))(d_{T^*}(a) - d_{T^*}(x)) \\\\\n",
    "\\end{eqnarray*}$\n",
    "\n",
    "If $f(a) > f(x)$ then $C(T^{**}) < C(T^*)$, which is a contradiction. So this means that we can swap $a$ and $x$ without changing the cost and thus some optimal solution has $x$ as a maximum depth leaf.\n",
    "\n",
    "<img src = \"huffman_exchange_argument.jpg\" width = \"30%\">\n",
    "\n",
    "Now why are $x$ and $y$ siblings? Well, first we can observe that every leaf in an optimal tree has a sibling. If not, we can reduce the encoding cost of some character. Now we can apply the same swapping argument as above to establish that $y$ is a sibling of $x$ in some optimal solution.\n",
    "\n",
    "\n",
    "**Optimal Substructure**: Let $\\Sigma' = \\Sigma - \\{x, y\\} \\cup \\{z\\}$, where $z\\not\\in \\Sigma$ is a character with frequency $f(z) = f(x) + f(y)$. If $T'$ is an optimal encoding for $\\Sigma'$, then an optimal encoding $T$ for $\\Sigma$ can be constructed from $T'$ by replacing the leaf representing $z$ with an internal node that has $x, y$ as children. \n",
    "\n",
    "**Proof**: We first make a useful observation of the relationship between the cost of $T$ and $T'$. Observe that:\n",
    "\n",
    "$\\begin{eqnarray*}\n",
    "C(T) &=& \\sum_{\\sigma\\in\\Sigma} f(\\sigma)d_T(\\sigma) \\\\\n",
    "&=& f(x)d_T(x) + f(y)d_T(y) + \\sum_{\\sigma\\in\\Sigma - \\{x,y\\}} f(\\sigma)d_T(\\sigma) \\\\\n",
    "&=& (f(x)+f(y))(1+d_T(z)) + \\sum_{\\sigma\\in\\Sigma - \\{x,y\\}} f(\\sigma)d_T(\\sigma) \\\\\n",
    "&=& (f(z))(1+d_T(z)) + \\sum_{\\sigma\\in\\Sigma - \\{x,y\\}} f(\\sigma)d_T(\\sigma) \\\\\n",
    "&=& f(z) + C(T') \\\\\n",
    "\\end{eqnarray*}$\n",
    "\n",
    "Suppose that $T$ was not optimal, and that there was some other tree $Z$ with $C(Z) < C(T)$. We can assume that $Z$ must have the two smallest frequency characters as siblings at maximum depth as established above. Now let's construct  \n",
    "$Z'$ by removing $x, y$ and adding $z$ with $f(z) = f(x)+f(y)$). $Z'$ is an encoding for $\\sigma'$, and we have that $C(Z) = f(z) + C(Z')$. By our assumption $C(Z) < C(T)$, so $f(z) + C(Z') < f(z) + C(T')$ using the observation above. But this is a contradiction to the optimality of $T'$ since we now have that $C(Z') < C(T').$\n",
    "\n",
    "Thus Huffman coding produces an optimal prefix-free encoding. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Decoding\n",
    "\n",
    "So how do we use Huffman coding in practice?\n",
    "\n",
    "Given a document $D$, we would compute frequencies and then construct an encoding tree $T$. Then to store the compressed version of $D$ we save the encoding of $\\Sigma$, the tree $T$ and the encoded version of $D$. To decode a document, we would read bits sequentially and traverse $T$, emitting the appropriate character from $\\Sigma$ whenever we hit a leaf. \n",
    "\n",
    "What is the worst-case work of decoding a document?\n",
    "\n",
    "<img src = \"encoding_trees.jpg\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$00000000010110111 \\rightarrow \\langle A, A, A, A, A, A, A, A, A, B, C, D\\rangle$\n",
    "\n",
    "- We start at the root, and descend the tree until we reach a leaf.\n",
    "- Then, we return to the root and repeat\n",
    "\n",
    "So, if the input has $n$ bits, we will visit each bit exactly once.\n",
    "\n",
    "$\\Rightarrow O(n)$\n",
    "\n",
    "which is equivalent to the total cost of the encoding tree:\n",
    "\n",
    "$\\Rightarrow O(C(T))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "David Huffman invented his coding algorithm as a student in [1951](https://en.wikipedia.org/wiki/Huffman_coding#History), so it has been around for about 70 years. Yet it is still ubiquitous! \n",
    "\n",
    "Huffman coding is optimal in the sense that no other prefix code can achieve a shorter average code length. In practice we must identify the best alphabet to use for the coding, i.e., finding the best way to decompose a file into binary \"blocks\" to get good compression.\n",
    "\n",
    "Both [ZIP](https://en.wikipedia.org/wiki/Zip_file_format) and [MP3](http://www.mp3-tech.org/programmer/docs/mp3_theory.pdf) file formats make use of Huffman coding as a last step after numerous preprocessing steps.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "rise": {
   "autolaunch": true,
   "controls": false,
   "enable_chalkboard": true,
   "scroll": true,
   "theme": "simple",
   "transition": "fade"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
