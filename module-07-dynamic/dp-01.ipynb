{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "div#notebook {\n",
       " font-family: \"Exo_2\", sans-serif;\n",
       "}\n",
       "\n",
       ".rendered_html h1,\n",
       ".text_cell_render h1 {\n",
       " color: #126dce;\n",
       " font-size: 220%;\n",
       " text-align: center;\n",
       " font-weight: lighter;\n",
       "}\n",
       ".rendered_html h2,\n",
       ".text_cell_render h2 {\n",
       " text-align: center;\n",
       " font-size: 170%;\n",
       " color: #126dce;\n",
       " font-style: normal;\n",
       " font-weight: lighter;\n",
       "}\n",
       ".rendered_html h3,\n",
       ".text_cell_render h3 {\n",
       " font-size: 150%;\n",
       " color: #126dce;\n",
       " font-weight: lighter;\n",
       " text-decoration: italic;\n",
       " font-style: normal;\n",
       "}\n",
       ".rendered_html h4,\n",
       ".text_cell_render h4 {\n",
       " font-size: 120%;\n",
       " color: #126dce;\n",
       " font-weight: underline;\n",
       " font-style: normal;\n",
       "}\n",
       ".rendered_html h5,\n",
       ".text_cell_render h5 {\n",
       " font-size: 100%;\n",
       " color: #2f2f2f;\n",
       " font-weight: lighter;\n",
       " text-decoration: underline;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# setup\n",
    "from IPython.core.display import display,HTML\n",
    "display(HTML('<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>'))\n",
    "display(HTML(open('rise.css').read()))\n",
    "\n",
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\", font_scale=1.5, rc={'figure.figsize':(12, 6)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CMPS 6610\n",
    "# Algorithms\n",
    "\n",
    "## Dynamic Programming\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Today's agenda:\n",
    "\n",
    "- \"Dynamic Programming\" Paradigm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So far, we've looked at 3 different paradigms of algorithm design:\n",
    "\n",
    "- Divide and Conquer\n",
    "- Brute Force\n",
    "- Greedy\n",
    "\n",
    "(Randomization can be added to any of these.)\n",
    "\n",
    "Divide and Conquer and Greedy both had a restriction to them in that we always recurse on one or more solutions to *fixed size* subproblems.\n",
    "\n",
    "In certain cases, for example using a greedy approach for the Knapsack Problem, this prevented us from reaching an optimal solution.\n",
    "\n",
    "What if we generalized our approach to consider **all possible** subproblems? This is sort of a hybrid of brute force and Greedy/Divide and Conquer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 0-1 Knapsack\n",
    "\n",
    "Suppose there are $n$ objects, each with a *value* $v_i$ and *weight* $w_i$. You have a \"knapsack\" of capacity $W$ and want to fill it with a set of objects $X \\subseteq [n]$ so that $w(X) \\leq W$ and $v(X)$ is maximized. \n",
    "\n",
    "We saw previously that a greedy approach works only if we're allowed to take fractional parts of the objects. The problem was that a greedy approach didn't really take leftover capacity into account. \n",
    "\n",
    "Recall that for greedy algorithms to be correct, we needed to prove that the greedy choice combined with an optimal solution for a smaller subproblem was also optimal (the **optimal substructure** property).\n",
    "\n",
    "Fractional Knapsack had the greedy choice property, but 0-1 Knapsack did not. Why?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can give a simple counterexample with 2 objects that have weights/values $(10, 5), (9.999, 3)$ with $W=5.$\n",
    "\n",
    "|index |value|weight|\n",
    "|------|------|-----|\n",
    "|0     | 10    |5    |\n",
    "|1     | 9.999     |3    |\n",
    "    \n",
    "The problem is that the greedy choice to maximize value/weight is incorrect because we can have leftover capacity. We really need to look at *all possible* choices of objects and their associated optimal solutions. \n",
    "\n",
    "Let $OPT(S, W)$ be an optimal solution to the Knapsack problem for a set of objects $S$ and capacity $W$. We started with $n$ objects and capacity $W$ so we are interested in finding $OPT([n], W)$. \n",
    "\n",
    "Now, we can make the following simple observation: if object $n$ is in the optimal solution, then $OPT([n], W)=\\{n\\} \\cup OPT([n-1], W-w(n)).$ If it isn't, then $OPT([n], W) = OPT([n-1], W)$.\n",
    "\n",
    "**Optimal Substructure for Knapsack**: For any set of objects $[n]$ and $W>0$, we have\n",
    "\n",
    "$$v(OPT(n, W)) = \\max \\{v(n) + v(OPT([n-1], W - w(n))), \\\\~~~~~~v(OPT(n-1, W))\\}.$$\n",
    "\n",
    "In a way, this really isn't saying much. Put plainly we're just saying that the optimal solution either contains object $n$ or it doesn't.\n",
    "\n",
    "For the example above, we have that:\n",
    "\n",
    "$\\begin{eqnarray*}\n",
    "v(OPT(1, 5)) &=& \\max\\{v(1) + v(OPT(0, 2)), v(OPT(0, 5))\\} \\\\\n",
    "&=& \\max\\{10, 9.999\\} \\\\\n",
    "&=& 10. \\\\\n",
    "\\end{eqnarray*}$\n",
    "\n",
    "Does this give us an algorithm? It is easy to write this in SPARC:\n",
    "\n",
    "$\\mathit{knapsack~~n~~W} = \\\\\n",
    "~~~~~\\mathtt{if}~~~n = 0\\\\\n",
    "~~~~~~~~~~0 \\\\\n",
    "~~~~~\\mathtt{if}~~~n = 1 \\\\\n",
    "~~~~~~~~~~\\mathtt{if}~~~w(1) \\leq W\\\\\n",
    "~~~~~~~~~~~~~~~v(1) \\\\\n",
    "~~~~~~~~~~\\mathtt{else}~~~0 \\\\\n",
    "~~~~~\\mathtt{else} \\\\\n",
    "~~~~~~~~~~\\mathtt{if}~~~w(n) \\geq W\\\\\n",
    "~~~~~~~~~~~~~~~~~~~~\\mathit{knapsack ~~n-1 ~~ W}\\\\\n",
    "~~~~~~~~~~\\mathtt{else}\\\\\n",
    "~~~~~~~~~~~~~~~~~~~~\\max\\{\\mathit{v(n)+knapsack~~n-1~~W-w(n)},~~\\mathit{knapsack~~n-1~~W}\\} \\\\\n",
    "$\n",
    "\n",
    "We can see that our optimal substructure recurrence depends both on the number of objects as well as their weights. \n",
    "\n",
    "The number of recursive calls doubles in every recursion. But suppose all items have weight 1 - is there a glaring inefficiency we can fix? Let's consider the recursion tree:\n",
    "\n",
    "<img src=\"knapsack_recursion_tree.jpg\" width=\"70%\">\n",
    "\n",
    "If we blindly recompute the redundant calls when they are encountered, then we will do $\\Omega(2^n)$ work and $O(n)$ span even if we can take all the items.  \n",
    "\n",
    "However, suppose that whenever we need to compute $OPT(i, w)$, we compute it once and save the result for later use (e.g., in a suitable data structure) -- this is called *memoization*. Then, we no longer have a binary tree but rather a **directed acyclic graph** or **DAG**.\n",
    "\n",
    "\n",
    "<img src=\"knapsack_recursion_dag.jpg\" width=\"70%\">\n",
    "\n",
    "\n",
    "\n",
    "The number of nodes in this DAG will allow us to determine the work of this algorithm, and the longest path in the DAG will allow us to determine the span. \n",
    "\n",
    "\n",
    "\n",
    "<br><br>\n",
    "\n",
    "When performing memoization, we can either proceed **top-down** or **bottom-up**:\n",
    "\n",
    "- **top-down**: use recursion solution as usual, but maintain a hash table to quickly check if a subproblem has been solved.\n",
    "\n",
    "- **bottom-up**: start with solutions to smallest subproblems and proceed to larger instances. This is typically implemented by filling a table.\n",
    "\n",
    "|index |value|weight|\n",
    "|------|------|-----|\n",
    "|0     | 10   |5    |\n",
    "|1     | 6    | 3 |\n",
    "|2     | 6    | 2 |\n",
    "\n",
    "\n",
    "Optimal solution is 12 (second and third items)\n",
    "<br><br>\n",
    "\n",
    "Consider this table: number of items to include (rows) by weight (cols)\n",
    "\n",
    "\n",
    "| |0 |1 |2 |3 |4 |5 |\n",
    "|-|-|-|-|-|-|-|\n",
    "|0|0 |0 |0 |0 |0 |0 |\n",
    "|1|0 |0 |0 |0 |0 |10|\n",
    "|2|0 |0 |0 |6 |6 |10|\n",
    "|3|0 |0 |6 |6 |6 |**12** |\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 10, 10, 10], [0, 10, 10, 10], [0, 10, 10, 16]]\n",
      "16\n",
      "10\n",
      "[[0, 0, 0, 0, 0, 10], [0, 0, 0, 9.999, 9.999, 10]]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def recursive_knapsack(objects, i, W):\n",
    "    v, w = objects[i]\n",
    "    if (i == 0):\n",
    "        if (w <= W):\n",
    "            return(v)\n",
    "        else:\n",
    "            return(0)\n",
    "    else:\n",
    "        if (w <= W):\n",
    "            take = v + recursive_knapsack(objects, i-1, max(W-w, 0))\n",
    "            dont_take = recursive_knapsack(objects, i-1, W)\n",
    "            return(max(take, dont_take))\n",
    "        elif (W == 0):\n",
    "            return(0)\n",
    "        else:\n",
    "            return(recursive_knapsack(objects, i-1, W))\n",
    "\n",
    "def tabular_knapsack(objects, W):\n",
    "    n = len(objects)\n",
    "    # we'll rely on indices to also represent weights, so we'll index from 1...W \n",
    "    # in the weight dimension of the table\n",
    "    OPT = [[0]*(W+1)]\n",
    "    \n",
    "    #print(objects[0][1])\n",
    "    # initialize the first row of the table\n",
    "    for w in range(W+1):\n",
    "        if (objects[0][1] <= w):\n",
    "            OPT[0][w] = objects[0][0]\n",
    "        else:\n",
    "            OPT[0][w] = 0\n",
    "    \n",
    "    # use the optimal substructure property to compute increasingly larger solutions\n",
    "    for i in range(1,n):\n",
    "        OPT.append([0]*(W+1))\n",
    "        v_i, w_i = objects[i]\n",
    "        for w in range(W+1):\n",
    "            if (w_i <= w):\n",
    "                OPT[i][w] = max(v_i + OPT[i-1][w-w_i], OPT[i-1][w])\n",
    "            else:\n",
    "                OPT[i][w] = OPT[i-1][w]\n",
    "               \n",
    "    print(OPT)\n",
    "    return(OPT[n-1][W])\n",
    "\n",
    "W = 3\n",
    "objects = [(10,1), (6,3), (6,2)]\n",
    "print(tabular_knapsack(objects, W))\n",
    "\n",
    "\n",
    "W = 5\n",
    "objects = [(10, 5), (9.999, 3)]\n",
    "n = len(objects)-1\n",
    "print(recursive_knapsack(objects.copy(), n, W))\n",
    "print(tabular_knapsack(objects.copy(), W))\n",
    "\n",
    "W = 1000\n",
    "objects = [(i, i) for i in range(1, 500000)]\n",
    "n = len(objects)-1\n",
    "#print(recursive_knapsack(objects, n, W))\n",
    "print(tabular_knapsack(objects, W))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "There are at most $O(nW)$ nodes in this DAG, and the longest path is $O(n)$. Each node requires $O(1)$ work/span, so the work is $O(nW)$ and the span is $O(n)$. Is this efficient?\n",
    "\n",
    "Well, not really. We need exponential time in the input size of $W$. We get only $\\log_2 W$ bits as input, but take time proportional to $W$. \n",
    "\n",
    "This isn't completely satisfying, but if it makes you feel better we do not know of any efficient algorithm for the 0-1 Knapsack problem (more on this at the end of the semester). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Elements of Dynamic Programming\n",
    "\n",
    "This is what we call **dynamic programming**. The elements of a dynamic programming algorithm are:\n",
    "\n",
    "- Optimal Substructure\n",
    "- Recursion DAG\n",
    "\n",
    "The correctness of the dynamic programming approach follows from the optimal substructure property (i.e., induction). If we can prove that the optimal substructure property holds, and that we compute a solution by correctly implementing this property then our solution is optimal.\n",
    "\n",
    "As with divide and conquer algorithms, achieving a good work/span can be tricky. We can minimize redundant computation by memoizing solutions to all subproblems. This can be done *top-down* by saving the result of a recursive call the first time we encounter it. Or, we can compute the optimal substructure property *bottom-up* by starting with the base case(s) and working our way up.\n",
    "\n",
    "Can we derive the number of nodes in the DAG using the optimal substructure property?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Work and Span in Dynamic Programming\n",
    "\n",
    "Since we memoize the solution to every distinct subproblem, the number of nodes in the DAG is equal to the number of distinct subproblems considered. \n",
    "\n",
    "The longest path in the DAG represents the span of our dynamic programming algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why \"Dynamic Programming\"?\n",
    "\n",
    "The mathematician Richard Bellman coined the term [\"dynamic programming\"](https://en.wikipedia.org/wiki/Dynamic_programming) to describe the recursive approach we just showed. The optimal substructure property is sometimes referred to as a \"Bellman equation.\" But why did he call it dynamic programming?\n",
    "\n",
    "There is some [folklore](https://en.wikipedia.org/wiki/Dynamic_programming#History) around the exact reason. But it could possibly be because \"dynamic\" is a really dramatic way to describe the search weaving through the DAG. The term \"programming\" was used in the field of optimization in the 1950s to describe an optimization approach (e.g., linear programming, quadratic programming, mathematical programming). \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "rise": {
   "autolaunch": true,
   "controls": false,
   "enable_chalkboard": true,
   "scroll": true,
   "theme": "simple",
   "transition": "fade"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
